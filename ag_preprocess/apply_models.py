# Apply statistical models (as estimated by climate-soybeans in R)
# to yearly growing-season climate output.
# FIXME: Currently only operates with a single model
# %%
from matplotlib import pyplot as plt
import importlib
import numpy as np
import pandas as pd
import xarray as xr
import cftime
import tqdm
import os
import glob
import re
import copy
import datetime
import numba
from numba import jit,prange
import rpy2.robjects

sys.path.append("../")
import pooled_stats 
# %% [markdown]
# ### Setup

# %%
# infolder = "../external/data/xavier/daily_all/"
baseinfolder = "../output_ag/dd_calc/"
baseoutfolder = "../output_ag/ag_vars/"

crops = ["single","maize"]
# crop = "single"

cropstrdict = {"single" : "Soy", "maize" : "2nd crop Maize"}

# calname = "ming595_mean"
calname = "Oct15-Mar1_Jan15-Jun15"

tempname = "temp"
tmaxname = "tmax"
tminname = "tmin"
precname = "prec"
vpdname = "vpd"

# calfolder = "fixed_calendars/"+calname+"/"
basecalfolder = baseinfolder + calname + "/"

# scens       =   next(os.walk(basecalfolder))[1]

# Default behavior is future scenarios minus historical
# Set ifutdelta to True for difference within scenarios
ifutdelta   =   True

fscens      =   ["rcp8.5_seg", "rcp8.5_weg", "rcp8.5_cmp", "rcp2.6_seg", "rcp2.6_weg", "rcp2.6_cmp"]
hscen       =   "historical"

allscens    =   [i for i in fscens]
allscens.append(hscen)

enscodes    =   ["005","006", "008", "009"]

fsyear = 2035
feyear = 2050
hsyear = 1991
heyear = 2005

if ifutdelta:
    fsyear = 2032
    feyear = 2050
    hsyear = 2012
    heyear = 2030
    


basevalgdd = 10.0
basevaledd = 30.0    

# RDS file containing the estimated R lm() models
# modelsfname = "../../climate-soybeans/models/fixed_calendar/model.ming595_yearly_fill.xavier.single.2.rds"
modelsfname = "../../climate-soybeans/models/fixed_calendar/model.v3.ming595_yearly_fill.xavier.single.2.rds"
modelname = "fit.fe.gddedd"
modelstring = "GDD+EDD"
# modelname = "fit.anom.gddedd"
# modelstring = "GDD+EDD"
# modelname = 'fit.anom.gddeddvpd.prec2'
# modelstring = "GDD+EDD+VPD+Prec"
# modelname = 'fit.anom.gddeddvpd' # FIXME: Something's wrong with VPD
# modelstring = "GDD+EDD+VPD"


# Dictionary translating variables as they appear in the 
# R model objects to the names in the NetCDF datasets
modelvardict = {
    "gdd1030dm" : "gdd",
    "edd30dm" : "edd",
    "vpdmeandm" : "vpdmean",
    "precmean" : "precmean",
    "I(precmean^2)" : "precmean2"
    }


metadict = {
    "tempmean" : {"long_name" : "Mean temperature", "units" : "°C"},
    "tmaxmean" : {"long_name" : "Maximum daily temperature", "units" : "°C"},
    "tminmean" : {"long_name" : "Minimum daily temperature", "units" : "°C"},
    "precmean" : {"long_name" : "Mean daily precipitation", "units" : "mm/day"},
    "vpdmean" : {"long_name" : "Mean daily vapour pressure deficit", "units" : "hPa"},
    "gdd" : {"long_name" : "Season GDD (10°C-30°C)", "units" : "°C day"},
    "edd" : {"long_name" : "Season EDD (10°C-30°C)", "units" : "°C day"},
    "agestimate" : {"long_name" : "yield change", "units" : "%"}
}

# Output file suffix (crop + outfnamesuf)
outfnamesuf = ".allscens.estimated.nc"
if ifutdelta:
    outfnamesuf = ".futdelta." + str(hsyear) + str(heyear) + "-" + str(fsyear) + str(feyear) + ".allscens.estimated.nc"

# Dirty override of the scenario counter, can be used to restart runs
ioverscen = False
# ioverscen = True
overscenindex = 2
if ioverscen:
    print("====================================================\n===== WARNING: Skipping to scenario index " + str(overscenindex) + " ========\n====================================================")

#%% Function definitions    ===============================================================

# Adds metadata to several variables based on a dictionary
def add_meta_dict(ds,metadict):
    for varname in metadict.keys():
        if varname in ds.data_vars:
            ds[varname] = ds[varname].assign_attrs(metadict[varname])
    return(ds)

# Reads a R model coefficient table from an RDS file containing model fit variables
# as generated by climate-soybeans
# fname = "/media/gabriel/hd1_6tb/backup/gabriel/transicao/doutorado/climate-soybeans/models/fixed_calendar/model.ming595_yearly_fill.xavier.single.2.rds"
# fname = modelsfname
# modname = "fit.anom.gddedd"
# modname = "fit.fe.gddedd"
def read_R_model_table(fname,modname):
    if "rpy2.robjects" not in sys.modules:
        raise NameError("Remember to import rpy2.robjects")
    R = rpy2.robjects.r

    models = R.readRDS(fname)

    model = models.rx2[modname]
    if 'lm' in list(model.rclass):
        smodel = R.summary(model)
        rcoeftable = smodel.rx2["coefficients"]
        rtermnames = R.rownames(rcoeftable)
        rcolnames = R.colnames(rcoeftable)

        coefsdf = pd.DataFrame(np.asarray(rcoeftable))
        coefsdf.index = rtermnames
        coefsdf.columns = rcolnames
    elif "felm" in list(model.rclass):
        rcoefmeans = model.rx2["coefficients"]
        rcoefses = model.rx2["se"]
        coefsarr = np.vstack((np.asarray(rcoefmeans).T.squeeze(),np.asarray(rcoefses))).T

        rtermnames = R.rownames(rcoefmeans)
        colnames = ['Estimate','Std. Error']

        coefsdf = pd.DataFrame(coefsarr)
        coefsdf.index = rtermnames
        coefsdf.columns = colnames

    return(coefsdf)

# print(read_R_model_table(modelsfname,modelname))
# Reads a R model coefficient table from an RDS file containing model fit variables
# as generated by climate-soybeans and converts it to a xarray Dataset with means
# and variances
def read_R_model_dataset(modelsfname, modelname, modelvardict = None):
    coeftable = read_R_model_table(modelsfname,modelname)

    coeftable["variance"] = coeftable["Std. Error"]**2 
    coeftable = coeftable.drop(["(Intercept)", "year"], errors="ignore")[["Estimate","variance"]]
    coeftable = coeftable.T

    if modelvardict is not None:
        coeftable = coeftable.rename(modelvardict, axis = 1)

    coefdsmeans = xr.Dataset(coeftable.loc["Estimate"])
    coefdsvariances = xr.Dataset(coeftable.loc["variance"])

    coefds = pooled_stats.combine_dataset_variances_generic(coefdsmeans,coefdsvariances)
    return(coefds)


# Opens a dataset and adds scenario and member dimensions with metadata
def meta_open_dataset(fname,scen,enscode):
    ds = xr.open_dataset(fname)
    ds = ds.assign_coords({
        "year":ds.attrs["harvest_year"],
        "scenario" : scen,
        "member" : enscode
        }).expand_dims(["year","scenario","member"])
    return(ds)

# Opens a dataset concatenating all files in an ensemble member's folder,
# adding scenario and member metadata
def dataset_open_ens_folder(basecalfolder, enscode, scen, crop):
    ensfolder = basecalfolder + scen + "_" + enscode + "/"
    listensds = [meta_open_dataset(fname,scen,enscode) for fname in glob.glob(ensfolder + "/" + crop + ".*.nc")]
    ensds = xr.combine_nested(listensds, concat_dim=["year"])
    ensds = ensds.sortby("year")
    return(ensds)

# Adds a suffix to all variables in a Dataset
def add_suf(ds,suf):
    return(ds.rename({i:(i + suf) for i in ds.data_vars}))

# Removes a suffix from all variables in a Dataset
def rem_suf(ds,suf):
    return(ds.rename({i:(re.sub("(.*)"+suf+"$","\g<1>",i)) for i in ds.data_vars}))

# Calculates mean and variances of all variables in a Dataset, 
# appending "_var" to the variance's variable names
def calc_ds_mean_and_var(allinds, dims = ["year","member"]):
    # Means and variances in separate Datasets
    meaninds = allinds.mean(keep_attrs = True, dim = dims)
    varinds = allinds.var(keep_attrs = True, ddof = 1, dim = dims)
    varinds = add_suf(varinds, "_var")

    # Combine and add number of observations
    alloutds = xr.merge([meaninds,varinds])
    alloutds.attrs['nobs_var'] = np.prod([len(allinds[d]) for d in dims])
    return(alloutds)

#Calculate GDD and EDD as new variables in a Dataset that has tempgdds
def calc_gdd_edd(inds,basevalgdd,basevaledd):
    inds["edd"] = inds["tempgdds"].sel(tmp = basevaledd)
    inds["gdd"] = inds["tempgdds"].sel(tmp = basevalgdd) - inds["tempgdds"].sel(tmp = basevaledd)

    inds["edd"].attrs["basevaledd"] = basevaledd
    inds["gdd"].attrs["basevalgdd"] = basevalgdd
    return(inds)

# Converts specified units from a Dataarray, using an optional exponent for higher moments (e.g. variances)
# We're not enforcing unit names here, just converting select ones
# For example, Pa/s and Pa s-1 won't be made the same
def convert_units(da, exponent = 1):
    if da.attrs['units'] == "kg m-2 s-1":
        # Convert from kg m-2 s-1 to m/s
        # da.values = da.values/1000
        da.values = da.values*(0.001**exponent)
        da.attrs['units'] = "m/s"
    else:
        da = da
    return(da)

# Applies a single model, ignoring variances and assuming all derived model
# terms are already calculated (e.g. squared variable) and have 
# properly named variables
# FIXME: Figure out a good way to calculate estimate variances
def apply_model_novar(ds,mds):
    (dsmeans, dsvariances) = pooled_stats.split_dataset_variances_generic(ds)

    (mdsmeans, mdsvariances) = pooled_stats.split_dataset_variances_generic(mds)


    # DataArray with estimated means
    estdameans = pooled_stats.sum_all_variables(dsmeans*mdsmeans)

    # Exponentiate since models are log
    estdameans = (100.0*(np.exp(estdameans)-1))

    return(estdameans)
#%% ============================ MAIN SCRIPT
# TODO: We must calculate anomalies of variables instead of levels first,
# before the deltas.
# Those anomalies should be in relation to the historical period mean,
# regardless if we are making future deltas.
# If we are calculating Fut-Hist, the average anomaly on the historical
# period will be 0, but the variance won't
# This means that our Yield variable of a given year (in the future or not)
# will be how much % more than the average yield of the historical yields.
# This has the major consequence of making the deltas be difference in percentages (p.p.),
# not actual percent differences.
# This will require having a historical reference period even when calculating
# deltas between future periods, so maybe calling P1 and P2 "hist" and "fut" like 
# it is now will be confusing. 

# crop = crops[0]
for crop in crops:
    print(crop)
    cropstr = cropstrdict[crop]
    print("Opening climate scenarios...")
    # Open all future and historical data in separate big datasets
    # listallds = [[dataset_open_ens_folder(basecalfolder, enscode, scen, crop) for scen in allscens] for enscode in enscodes]
    flistallds = [[dataset_open_ens_folder(basecalfolder, enscode, scen, crop) for scen in fscens] for enscode in enscodes]
    fbiginds = xr.combine_nested(flistallds, concat_dim=["member","scenario"])

    if ifutdelta:
        hbiginds = fbiginds.copy()
    else:
        hlistallds = [[dataset_open_ens_folder(basecalfolder, enscode, scen, crop) for scen in [hscen]] for enscode in enscodes]
        hbiginds = xr.combine_nested(hlistallds, concat_dim=["member","scenario"])

    # Selecting years    
    fbiginds = fbiginds.sel(scenario = fscens, year = slice(fsyear,feyear))

    if ifutdelta:
        hbiginds = hbiginds.sel(scenario = fscens,  year = slice(hsyear,heyear))
    else:
        hbiginds = hbiginds.sel(scenario = hscen,  year = slice(hsyear,heyear))

    # Calculating squared precmean
    hbiginds["precmean2"] = hbiginds["precmean"]**2
    fbiginds["precmean2"] = fbiginds["precmean"]**2

    # Calculate GDD and EDD (levels)
    hbiginds = calc_gdd_edd(hbiginds, basevalgdd, basevaledd)
    fbiginds = calc_gdd_edd(fbiginds, basevalgdd, basevaledd)

    # TODO: Ideally we would estimate the models before aggregating,
    # but since these are anomaly models does it make sense to work with
    # actual levels before calculating differences?

    # Calculate means and variances
    hmvds = calc_ds_mean_and_var(hbiginds, dims=["year","member"])
    fmvds = calc_ds_mean_and_var(fbiginds, dims=["year","member"])

    print("Performing t-tests...")
    # Differences compared to historical, with t-test pvalues
    deltattests = pooled_stats.calc_diff_ttest_generic(fmvds, hmvds, hmvds.attrs["nobs_var"])

    # Just the p-values of climate variables t-tests
    deltapvals = deltattests[[i for i in deltattests.data_vars if re.match(".*_pval",i)] ]

    # Differences from historical for climate variables only
    deltaclim = pooled_stats.addsub_ds_variances(fmvds,hmvds, "sub")

    print("Applying statistical models...")
    # Read model coefficients from R (using rpy2) and convert them 
    # to a Dataset with variables renamed and variances added
    modelds = read_R_model_dataset(modelsfname, modelname, modelvardict)
    # modelds = read_R_model_dataset(modelsfname, "fit.anom.gddeddvpd.prec2", modelvardict)

    # Apply a single model without calculating variances
    estdelta = apply_model_novar(deltaclim,modelds)
    estdelta.name = "agestimate"
    estdelta = estdelta.assign_coords({"statmodel" : modelstring}).expand_dims("statmodel")

    # Append ag model estimates
    deltaclim = deltaclim.merge(estdelta)

    # Append climate t-test p-values
    deltaclim = deltaclim.merge(deltapvals)

    # Add metadata for some variables
    deltaclim = add_meta_dict(deltaclim, metadict)
    deltaclim["agestimate"].attrs["long_name"] = cropstr + " " + deltaclim["agestimate"].attrs["long_name"]

    # Output folder for that calendar
    outfolder = baseoutfolder + "/" + calname + "/" 

    # Create output folder
    os.makedirs(outfolder, exist_ok=True)

    # Main output file name
    # outfname = outfolder + crop + ".allscens.estimated.nc"
    outfname = outfolder + crop + outfnamesuf
     
    print("Writing output file...")
    # Write output
    deltaclim.to_netcdf(outfname)

#%%